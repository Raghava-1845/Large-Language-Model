{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlQuGjGQUe+SX5exAj8ncp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghava-1845/Large-Language-Model/blob/main/Encoder_%26_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ------------------\n",
        "# Data\n",
        "# ------------------\n",
        "src_word = \"thank you\"\n",
        "tgt_word = \"gracias\"\n",
        "\n",
        "START = \"^\"\n",
        "\n",
        "chars = sorted(set(src_word + tgt_word + START))\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "\n",
        "def encode(word):\n",
        "    return torch.tensor([char2idx[c] for c in word], dtype=torch.long)\n",
        "\n",
        "src = encode(src_word)\n",
        "tgt = encode(START + tgt_word)\n",
        "\n",
        "# ------------------\n",
        "# Encoder\n",
        "# ------------------\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embed(x).unsqueeze(1)\n",
        "        _, hidden = self.rnn(emb)\n",
        "        return hidden\n",
        "\n",
        "# ------------------\n",
        "# Decoder\n",
        "# ------------------\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embed(x).unsqueeze(0)\n",
        "        out, hidden = self.rnn(emb, hidden)\n",
        "        out = self.fc(out.squeeze(0))\n",
        "        return out, hidden\n",
        "\n",
        "# ------------------\n",
        "# Train\n",
        "# ------------------\n",
        "hidden_size = 32\n",
        "encoder = Encoder(len(chars), hidden_size)\n",
        "decoder = Decoder(len(chars), hidden_size)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(\n",
        "    list(encoder.parameters()) + list(decoder.parameters()),\n",
        "    lr=0.01\n",
        ")\n",
        "\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    hidden = encoder(src)\n",
        "    loss = 0\n",
        "    dec_input = tgt[0].unsqueeze(0)\n",
        "\n",
        "    for i in range(1, len(tgt)):\n",
        "        output, hidden = decoder(dec_input, hidden)\n",
        "        loss += loss_fn(output, tgt[i].unsqueeze(0))\n",
        "        dec_input = tgt[i].unsqueeze(0)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# ------------------\n",
        "# Inference\n",
        "# ------------------\n",
        "with torch.no_grad():\n",
        "    hidden = encoder(src)\n",
        "    dec_input = torch.tensor([char2idx[START]])\n",
        "    result = []\n",
        "\n",
        "    for _ in range(len(tgt) - 1):\n",
        "        output, hidden = decoder(dec_input, hidden)\n",
        "        idx = output.argmax().item()\n",
        "        result.append(idx2char[idx])\n",
        "        dec_input = torch.tensor([idx])\n",
        "\n",
        "print(\"Input:\", src_word)\n",
        "print(\"Output:\", \"\".join(result))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVuTSdPZu6y7",
        "outputId": "22841514-19f7-483b-8bde-605644478611"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: thank you\n",
            "Output: gracias\n"
          ]
        }
      ]
    }
  ]
}